{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Blockchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blockchain\n",
    "class blockchain:\n",
    "        def __init__(self):\n",
    "                self.chain = []\n",
    "                self.current_transactions = []\n",
    "                self.nodes = set()\n",
    "\n",
    "                # Create the genesis block\n",
    "                self.new_block(previous_hash=1, proof=100)\n",
    "\n",
    "        def register_node(self, address):\n",
    "                \"\"\"\n",
    "                Add a new node to the list of nodes\n",
    "                :param address: Address of node. Eg. 'http://\n",
    "                :return: None\n",
    "                \"\"\"\n",
    "        def urlparse(url):\n",
    "                return urlparse(url)\n",
    "        def valid_chain(self, chain):\n",
    "                \"\"\"\n",
    "                Determine if a given blockchain is valid\n",
    "                :param chain: A blockchain\n",
    "                :return: True if valid, False if not\n",
    "                \"\"\"\n",
    "                last_block = chain[0]\n",
    "                current_index = 1\n",
    "\n",
    "                while current_index < len(chain):\n",
    "                        block = chain[current_index]\n",
    "                        print(f'{last_block}')\n",
    "                        print(f'{block}')\n",
    "                        print(\"\\n-----------\\n\")\n",
    "                        # Check that the hash of the block is correct\n",
    "                        if block['previous_hash'] != self.hash(last_block):\n",
    "                                return False\n",
    "\n",
    "                        # Check that the Proof of Work is correct\n",
    "                        if not self.valid_proof(last_block['proof'], block['proof'], last_block['previous_hash']):\n",
    "                                return False\n",
    "\n",
    "                        last_block = block\n",
    "                        current_index += 1\n",
    "\n",
    "                return True\n",
    "        def resolve_conflicts(self):\n",
    "                \"\"\"\n",
    "                reutrn\"\"\"\n",
    "                neighbours = self.nodes\n",
    "                new_chain = None\n",
    "\n",
    "                # We're only looking for chains longer than ours\n",
    "                max_length = len(self.chain)\n",
    "\n",
    "                # Grab and verify the chains from all the nodes in our network\n",
    "                for node in neighbours:\n",
    "                        response = requests.get(f'http://{node}/chain')\n",
    "        def new_block(self, proof, previous_hash=None):\n",
    "                \"\"\"\n",
    "                Create a new Block in the Blockchain\n",
    "                :param proof: The proof given by the Proof of Work algorithm\n",
    "                :param previous_hash: Hash of previous Block\n",
    "                :return: New Block\n",
    "                \"\"\"\n",
    "                block = {\n",
    "                    'index': len(self.chain) + 1,\n",
    "                    'timestamp': time(),\n",
    "                    'transactions': self.current_transactions,\n",
    "                    'proof': proof,\n",
    "                    'previous_hash': previous_hash or self.hash(self.chain[-1]),\n",
    "                }\n",
    "\n",
    "                # Reset the current list of transactions\n",
    "                self.current_transactions = []\n",
    "        def new_transaction(self, maker, score, model,hyperparameters):\n",
    "                \"\"\"\n",
    "                Creates a new transaction to go into the next mined Block\n",
    "                :param maker: Address of the maker\n",
    "                :param score: Address of the score\n",
    "                :param model: model\n",
    "                :return: The index of the Block that will hold this transaction\n",
    "                \"\"\"\n",
    "                self.current_transactions.append({\n",
    "                    'maker': maker,\n",
    "                    'score': score,\n",
    "                    'model': model,\n",
    "                    'hyperparameter': hyperparameter\n",
    "                })\n",
    "\n",
    "                return self.last_block['index'] + 1\n",
    "        def proof_of_work(self, last_proof):\n",
    "                \"\"\"\n",
    "                Simple Proof of Work Algorithm:\n",
    "                 - Find a number p' such that hash(pp') contains leading 4 zeroes, where p is the previous p'\n",
    "                 - p is the previous proof, and p' is the new proof\n",
    "                :param last_proof: Previous Proof\n",
    "                :return: Current Proof\n",
    "                \"\"\"\n",
    "                proof = 0\n",
    "                while self.valid_proof(last_proof, proof) is False:\n",
    "                        proof += 1\n",
    "\n",
    "                return proof\n",
    "        def valid_proof(self, last_proof, proof):\n",
    "                \"\"\"\n",
    "                Validates the Proof: Does hash(last_proof, proof) contain 4 leading zeroes?\n",
    "                :param last_proof: Previous Proof\n",
    "                :param proof: Current Proof\n",
    "                :return: True if correct, False if not.\n",
    "                \"\"\"\n",
    "                guess = f'{last_proof}{proof}'.encode()\n",
    "                guess_hash = hashlib.sha256(guess).hexdigest()\n",
    "                return guess_hash[:4] == \"0000\"\n",
    "        def hash(self, block):\n",
    "                \"\"\"\n",
    "                Creates a SHA-256 hash of a Block\n",
    "                :param block: Block\n",
    "                \"\"\"\n",
    "                # We must make sure that the Dictionary is Ordered, or we'll have inconsistent hashes\n",
    "                block_string = json.dumps(block, sort_keys=True).encode()\n",
    "                return hashlib.sha256(block_string).hexdigest()\n",
    "        def last_block(self):\n",
    "                \"\"\"\n",
    "                Returns the last Block in the chain\n",
    "                :return: <dict> last Block\n",
    "                \"\"\"\n",
    "                return self.chain[-1]\n",
    "        def register_node(self, address):\n",
    "                \"\"\"\n",
    "                Add a new node to the list of nodes\n",
    "                :param address: Address of node. Eg. 'http://\n",
    "                :return: None\n",
    "                \"\"\"\n",
    "                parsed_url = urlparse(address)\n",
    "                self.nodes.add(parsed_url.netloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decentralized neural network\n",
    "class nn:\n",
    "        def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "                self.input_nodes = input_nodes\n",
    "                self.hidden_nodes = hidden_nodes\n",
    "                self.output_nodes = output_nodes\n",
    "                self.lr = learning_rate\n",
    "                self.weights_input_to_hidden = np.random.normal(0.0, self.input_nodes**-0.5,\n",
    "                                                                (self.input_nodes, self.hidden_nodes))\n",
    "                self.weights_hidden_to_output = np.random.normal(0.0, self.hidden_nodes**-0.5,\n",
    "                                                                        (self.hidden_nodes, self.output_nodes))\n",
    "                self.biases_hidden = np.zeros((1, self.hidden_nodes))   # bias for hidden layer\n",
    "                self.biases_output = np.zeros((1, self.output_nodes))   # bias for output layer\n",
    "        def train(self, features, targets):\n",
    "                n_records = features.shape[0]\n",
    "                delta_weights_i_h = np.zeros(self.weights_input_to_hidden.shape)\n",
    "                delta_weights_h_o = np.zeros(self.weights_hidden_to_output.shape)\n",
    "                delta_bias_h = np.zeros(self.biases_hidden.shape)\n",
    "                delta_bias_o = np.zeros(self.biases_output.shape)\n",
    "                for X, y in zip(features, targets):\n",
    "                        final_outputs, hidden_outputs = self.forward_pass_train(X)\n",
    "                        delta_weights_i_h, delta_weights_h_o, delta_bias_h, delta_bias_o = self.backpropagation(final_outputs, hidden_outputs, X, y, delta_weights_i_h, delta_weights_h_o, delta_bias_h, delta_bias_o)\n",
    "                self.update_weights(delta_weights_i_h, delta_weights_h_o, delta_bias_h, delta_bias_o, n_records)\n",
    "        def forward_pass_train(self, X):\n",
    "                hidden_inputs = np.dot(X, self.weights_input_to_hidden) + self.biases_hidden\n",
    "                hidden_outputs = self.activation_function(hidden_inputs)\n",
    "                final_inputs = np.dot(hidden_outputs, self.weights_hidden_to_output) + self.biases_output\n",
    "                final_outputs = self.activation_function(final_inputs)\n",
    "                return final_outputs, hidden_outputs\n",
    "        def backpropagation(self, final_outputs, hidden_outputs, X, y, delta_weights_i_h, delta_weights_h_o, delta_bias_h, delta_bias_o):\n",
    "                error = y - final_outputs\n",
    "                output_error_term = error\n",
    "                hidden_error = np.dot(self.weights_hidden_to_output, output_error_term)\n",
    "                hidden_error_term = hidden_error * hidden_outputs * (1 - hidden_outputs)\n",
    "                delta_weights_i_h += hidden_error_term * X[:, None]\n",
    "                delta_weights_h_o += output_error_term * hidden_outputs[:, None]\n",
    "                delta_bias_h += hidden_error_term\n",
    "                delta_bias_o += output_error_term\n",
    "                return delta_weights_i_h, delta_weights_h_o, delta_bias_h, delta_bias_o\n",
    "        def update_weights(self, delta_weights_i_h, delta_weights_h_o, delta_bias_h, delta_bias_o, n_records):\n",
    "                self.weights_hidden_to_output += self.lr * delta_weights_h_o / n_records\n",
    "                self.weights_input_to_hidden += self.lr * delta_weights_i_h / n_records\n",
    "                self.biases_hidden += self.lr * delta_bias_h / n_records\n",
    "                self.biases_output += self.lr * delta_bias_o / n_records\n",
    "        def activation_function(self, x):\n",
    "                return 1 / (1 + np.exp(-x))\n",
    "        def predict(self, X):\n",
    "                final_outputs, _ = self.forward_pass_train(X)\n",
    "                return final_outputs\n",
    "        def save(self):\n",
    "                np.save('weights_hidden_to_output', self.weights_hidden_to_output)\n",
    "                np.save('weights_input_to_hidden', self.weights_input_to_hidden)\n",
    "                np.save('biases_hidden', self.biases_hidden)\n",
    "                np.save('biases_output', self.biases_output)\n",
    "        def load(self):\n",
    "                self.weights_hidden_to_output = np.load('weights_hidden_to_output.npy')\n",
    "                self.weights_input_to_hidden = np.load('weights_input_to_hidden.npy')\n",
    "                self.biases_hidden = np.load('biases_hidden.npy')\n",
    "                self.biases_output = np.load('biases_output.npy')\n",
    "        def save_model(self):\n",
    "                self.save()\n",
    "                self.save_model_weights()\n",
    "        def save_model_weights(self):\n",
    "                np.save('weights_hidden_to_output', self.weights_hidden_to_output)\n",
    "                np.save('weights_input_to_hidden', self.weights_input_to_hidden)\n",
    "                np.save('biases_hidden', self.biases_hidden)\n",
    "                np.save('biases_output', self.biases_output)\n",
    "        def load_model(self):\n",
    "                self.load()\n",
    "                self.load_model_weights()\n",
    "        def load_model_weights(self):\n",
    "                self.weights_hidden_to_output = np.load('weights_hidden_to_output.npy')\n",
    "                self.weights_input_to_hidden = np.load('weights_input_to_hidden.npy')\n",
    "                self.biases_hidden = np.load('biases_hidden.npy')\n",
    "                self.biases_output = np.load('biases_output.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset for dnn\n",
    "dataset = pd.read_csv('data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make convolution neural network\n",
    "def make_cnn(dataset):\n",
    "        #split dataset into features and labels\n",
    "        X = dataset.iloc[:, :-1].values\n",
    "        y = dataset.iloc[:, -1].values\n",
    "        #normalize features\n",
    "        X = X/255\n",
    "        #reshape features\n",
    "        X = X.reshape(X.shape[0], 1, 28, 28).astype('float32')\n",
    "        #one hot encode labels\n",
    "        y = to_categorical(y)\n",
    "        #split into training and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "        #create model\n",
    "        model = Sequential()\n",
    "        #add convolutional layer\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(1, 28, 28)))\n",
    "        #add pooling layer\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        #add hidden layer\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        #add output layer\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "        #compile model\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        #fit model\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "        #evaluate model\n",
    "        scores = model.evaluate(X_test, y_test)\n",
    "        print('Accuracy: %.2f%%' % (scores[1]*100))\n",
    "        #save model\n",
    "        model.save_model()\n",
    "        return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make rnn\n",
    "def make_rnn(dataset):\n",
    "        #split dataset into features and labels\n",
    "        X = dataset.iloc[:, :-1].values\n",
    "        y = dataset.iloc[:, -1].values\n",
    "        #normalize features\n",
    "        X = X/255\n",
    "        #reshape features\n",
    "        X = X.reshape(X.shape[0], 28, 28).astype('float32')\n",
    "        #one hot encode labels\n",
    "        y = to_categorical(y)\n",
    "        #split into training and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "        #create model\n",
    "        model = Sequential()\n",
    "        #add rnn layer\n",
    "        model.add(LSTM(units=50, return_sequences=True, input_shape=(28, 28)))\n",
    "        model.add(LSTM(units=50))\n",
    "        #add output layer\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "        #compile model\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        #fit model\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "        #evaluate model\n",
    "        scores = model.evaluate(X_test, y_test)\n",
    "        print('Accuracy: %.2f%%' % (scores[1]*100))\n",
    "        #save model\n",
    "        model.save_model()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dnn\n",
    "def make_dnn(dataset):\n",
    "        #split dataset into features and labels\n",
    "        X = dataset.iloc[:, :-1].values\n",
    "        y = dataset.iloc[:, -1].values\n",
    "        #normalize features\n",
    "        X = X/255\n",
    "        #reshape features\n",
    "        X = X.reshape(X.shape[0], 1, 28, 28).astype('float32')\n",
    "        #one hot encode labels\n",
    "        y = to_categorical(y)\n",
    "        #split into training and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "        #create model\n",
    "        model = Sequential()\n",
    "        #add hidden layer\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        #add output layer\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "        #compile model\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        #fit model\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "        #evaluate model\n",
    "        scores = model.evaluate(X_test, y_test)\n",
    "        print('Accuracy: %.2f%%' % (scores[1]*100))\n",
    "        #save model\n",
    "        model.save_model()\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset for cnn\n",
    "dataset = pd.read_csv('data.csv')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a94588eda9d64d9e9a351ab8144e55b1fabf5113b54e67dd26a8c27df0381b3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
